version: "3.7"

# create pyspark to submit : from csv to SQL and neo4j

services:

    # mariadb
    mariadb:
      image: mariadb:latest
#      restart: always
      environment:
        MYSQL_ALLOW_EMPTY_PASSWORD: 'yes'
        MYSQL_DATABASE: exploreit
      ports:
        - '3306:3306'
      volumes:
        - ./db_persistence/mariadb:/var/lib/mysql
      networks:
        - default_net

    # neo4j
    neo4j:
      image: neo4j:5.10
      ports:
        - '7474:7474'
#        - '7473:7473'
        - '7687:7687'
      environment:
        - NEO4J_AUTH=neo4j/neo4jneo4j
        - NEO4J_server_memory_heap_initial__size=1G
        - NEO4J_server_memory_heap_max__size=2G
        - NEO4J_apoc_export_file_enabled=true
        - NEO4J_apoc_import_file_enabled=true
        - NEO4J_apoc_import_file_use__neo4j__config=true
        - NEO4JLABS_PLUGINS=["apoc", "graph-data-science"]
#        - NEO4J_PLUGINS=["graph-data-science"]
      volumes:
        - ./db_persistence/neo4j:/data
      networks:
        - default_net

    # mongodb
    mongodb:
      image: mongo:latest
      environment:
        MONGO_INITDB_DATABASE: exploreit
      volumes:
        - ./db_persistence/mongodb:/data/db
      ports:
        - '27017:27017'
      networks:
        - default_net


    # Spark with 2 workers
    spark-master:
        image: bitnami/spark:latest
        user: root # Run container as root container: https://docs.bitnami.com/tutorials/work-with-non-root-containers/
        hostname: spark
        networks:
            - default_net
        environment:
            - SPARK_MODE=master
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
#            - SPARK_USER=spark
        volumes:
            - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
            - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
        ports:
            - "8080:8080"
            - "7077:7077"

    spark-worker-1:
        image: bitnami/spark:latest
        user: root
        networks:
            - default_net
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
#            - SPARK_USER=spark
        volumes:
            - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
            - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

    spark-worker-2:
        image: bitnami/spark:latest
        user: root
        networks:
            - default_net
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
        volumes:
            - ../spark/app:/usr/local/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
            - ../spark/resources:/usr/local/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)


    #Jupyter notebook
    # jupyter-spark:
    #     image: jupyter/pyspark-notebook
    #     user: root
    #     environment:
    #       NB_USER: "root"
    #       NB_UID: 0
    #       NB_GID: 0
    #       NOTEBOOK_ARGS: --allow-root
    #     networks:
    #         - default_net
    #     ports:
    #       - "8888:8888"
    #       - "4040-4080:4040-4080"
    #     links:
    #       - "neo4j:neo4j"
    #       - "mariadb:mariadb"
    #       - "mongodb:mongodb"
    #     volumes:
    #       - ./notebooks:/home/root/work/notebooks/
    #       - ./spark/resources/data:/home/root/work/data/
    #       - ./spark/resources/jars:/home/root/work/jars/


#    navigo:
#        build:
#          context: ./navigo
#          dockerfile: Dockerfile
#
#        ports:
#          - "8000:8000"
#        networks:
#          - default_net

networks:
    default_net:
